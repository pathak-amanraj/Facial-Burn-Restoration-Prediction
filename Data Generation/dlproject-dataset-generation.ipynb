{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1504266,"sourceType":"datasetVersion","datasetId":885385,"isSourceIdPinned":false}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\nimport cv2\nimport numpy as np\nfrom pathlib import Path\nimport os\nimport random\nfrom scipy.ndimage import gaussian_filter, distance_transform_edt\nimport matplotlib.pyplot as plt\n\npath = kagglehub.dataset_download(\"ashwingupta3012/human-faces\")\nprint(\"Path to dataset files:\", path)\n\nclass RealisticBurnGenerator:\n    def __init__(self, output_dir=\"burn_augmented\", seed=None):\n        if seed is not None:\n            random.seed(seed)\n            np.random.seed(seed)\n        self.output_dir = output_dir\n        os.makedirs(output_dir, exist_ok=True)\n        os.makedirs(f\"{output_dir}/original\", exist_ok=True)\n        os.makedirs(f\"{output_dir}/with_burns\", exist_ok=True)\n\n    def detect_face_region(self, img):\n        h, w = img.shape[:2]\n        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(60, 60))\n        if len(faces) > 0:\n            face = max(faces, key=lambda x: x[2] * x[3])\n            x, y, fw, fh = face\n            shrink_w = int(fw * 0.08)\n            shrink_h = int(fh * 0.08)\n            x0 = x + shrink_w\n            y0 = y + shrink_h\n            fw = fw - 2 * shrink_w\n            fh = fh - 2 * shrink_h\n            return {\n                'x': x0, \n                'y': y0, \n                'w': fw, \n                'h': fh, \n                'center_x': x0 + fw // 2, \n                'center_y': y0 + fh // 2\n            }\n        return {\n            'x': int(w*0.3), \n            'y': int(h*0.25), \n            'w': int(w*0.4), \n            'h': int(h*0.5),\n            'center_x': w//2, \n            'center_y': h//2\n        }\n\n    def create_face_mask(self, img_shape, face_region):\n        h, w = img_shape[:2]\n        fx, fy, fw, fh = face_region['x'], face_region['y'], face_region['w'], face_region['h']\n        face_mask = np.zeros((h, w), dtype=np.float32)\n        face_mask[fy:fy+fh, fx:fx+fw] = 1.0\n        face_mask = cv2.GaussianBlur(face_mask, (0, 0), sigmaX=10, sigmaY=10)\n        cy, cx = face_region['center_y'], face_region['center_x']\n        yy, xx = np.mgrid[0:h, 0:w]\n        rx = fw / 2.0\n        ry = fh / 2.0\n        ellipse = (((xx - cx) / rx)**2 + ((yy - cy) / ry)**2) <= 1.0\n        ellipse_mask = ellipse.astype(np.float32)\n        ellipse_mask = cv2.GaussianBlur(ellipse_mask, (0, 0), sigmaX=8, sigmaY=8)\n        combined_mask = np.maximum(face_mask * 0.7, ellipse_mask)\n        combined_mask = cv2.GaussianBlur(combined_mask, (0, 0), sigmaX=6, sigmaY=6)\n        return combined_mask\n\n    def fractal_noise(self, shape, octaves=4, persistence=0.5):\n        h, w = shape\n        noise = np.zeros((h, w), dtype=np.float32)\n        frequency = 1.0\n        amplitude = 1.0\n        for _ in range(octaves):\n            n = np.random.rand(h, w)\n            n = gaussian_filter(n, sigma=max(1.0, (1.0 / frequency) * 3.0))\n            noise += n * amplitude\n            amplitude *= persistence\n            frequency *= 2.0\n        noise = (noise - noise.min()) / (noise.max() - noise.min() + 1e-12)\n        return noise\n\n    def create_burn_mask(self, img_shape, face_region, face_boundary_mask, size_factor=0.33):  # <--- Made LARGER!\n        h, w = img_shape[:2]\n        fx, fy, fw, fh = face_region['x'], face_region['y'], face_region['w'], face_region['h']\n        cx = random.randint(fx + fw//4, fx + 3*fw//4)\n        cy = random.randint(fy + fh//4, fy + 3*fh//4)\n        base_radius_x = int(fw * size_factor * random.uniform(0.7, 1.0))  # larger lower bound\n        base_radius_y = int(fh * size_factor * random.uniform(0.7, 1.0))\n        mask = np.zeros((h, w), dtype=np.float32)\n        yy, xx = np.mgrid[0:h, 0:w]\n        ellipse = (((xx - cx) / (base_radius_x + 1e-6))**2 + ((yy - cy) / (base_radius_y + 1e-6))**2)\n        mask_core = np.clip(1.0 - ellipse, 0.0, 1.0)\n        num_blobs = random.randint(4, 7)  # slightly more blobs\n        blobs = np.zeros_like(mask_core)\n        for _ in range(num_blobs):\n            ox = cx + random.randint(-base_radius_x//2, base_radius_x//2)\n            oy = cy + random.randint(-base_radius_y//2, base_radius_y//2)\n            r_x = int(base_radius_x * random.uniform(0.4, 0.8))\n            r_y = int(base_radius_y * random.uniform(0.4, 0.8))\n            ell = (((xx - ox) / (r_x + 1e-6))**2 + ((yy - oy) / (r_y + 1e-6))**2)\n            blobs += np.clip(1.0 - ell, 0.0, 1.0)\n        mask = np.clip(mask_core * 1.3 + blobs * 0.7, 0.0, 1.0)\n        noise = self.fractal_noise((h, w), octaves=5, persistence=0.6)\n        mask *= gaussian_filter(noise, sigma=6.0) * 1.2 + 0.3\n        mask = mask * face_boundary_mask\n        mask = gaussian_filter(mask, sigma=8.0)\n        mask = (mask - mask.min()) / (mask.max() - mask.min() + 1e-12)\n        mask = np.clip((mask - 0.13) / (1 - 0.13), 0.0, 1.0)\n        safety_mask = cv2.erode(face_boundary_mask, np.ones((15, 15), np.uint8), iterations=1)\n        mask = mask * safety_mask\n        return (mask * 255).astype(np.uint8)\n\n    def apply_burn(self, img, mask, severity='severe'):\n        result = img.copy().astype(np.float32)\n        h, w = img.shape[:2]\n        lab = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2LAB).astype(np.float32)\n        mask_float = mask.astype(np.float32) / 255.0\n        feathered = cv2.GaussianBlur(mask_float, (0, 0), sigmaX=15, sigmaY=15, borderType=cv2.BORDER_REFLECT)\n        dil = cv2.dilate(mask, np.ones((25, 25), np.uint8), iterations=1)\n        surround = (dil > 0) & (mask == 0)\n        surround_pixels = lab[surround]\n        if len(surround_pixels) > 0:\n            base_L, base_A, base_B = np.median(surround_pixels, axis=0)\n        else:\n            base_L, base_A, base_B = 150.0, 128.0, 128.0\n        params = {\n            # Intensify parameters for a harsher effect\n            'severe': {'L_mult': 0.45, 'A_shift': 38, 'B_shift': -24, 'char_factor': 0.9,'texture_amp': 0.98},\n        }\n        p = params['severe']\n        ys, xs = np.where(mask > 0)\n        if len(ys) == 0:\n            return img\n        y0, y1 = max(0, ys.min()-10), min(h, ys.max()+10)\n        x0, x1 = max(0, xs.min()-10), min(w, xs.max()+10)\n        sub_h, sub_w = y1 - y0, x1 - x0\n        noise = self.fractal_noise((sub_h, sub_w), octaves=5, persistence=0.65)\n        noise = gaussian_filter(noise, sigma=1.2)\n        noise = (noise - noise.min()) / (noise.max() - noise.min() + 1e-12)\n        mask_sub = (mask[y0:y1, x0:x1] / 255.0).astype(np.float32)\n        dist = distance_transform_edt(mask_sub)\n        centroid_weight = (dist.max() - dist) / (dist.max() + 1e-6)\n        centroid_weight = (centroid_weight - centroid_weight.min()) / (centroid_weight.max() - centroid_weight.min() + 1e-12)\n        for dy in range(sub_h):\n            for dx in range(sub_w):\n                my = y0 + dy\n                mx = x0 + dx\n                alpha = feathered[my, mx]\n                if alpha < 0.02: continue\n                tex = noise[dy, dx]\n                center_factor = centroid_weight[dy, dx] if centroid_weight.size else 0.0\n                # Strong color & luminance modifications\n                L_target = base_L * (p['L_mult'] * (0.91 + tex * p['texture_amp']))\n                A_target = base_A + p['A_shift'] * (0.76 + tex * 0.8) * (1 - center_factor * p['char_factor'])\n                B_target = base_B + p['B_shift'] * (0.82 + tex * 0.6) - center_factor * 13.0 * p['char_factor']\n                if p['char_factor'] > 0 and center_factor > 0.5:\n                    char_mix = min(1.0, (center_factor - 0.5) * 2.0 * p['char_factor'])\n                    L_target *= (0.33 + 0.67 * (1 - char_mix))\n                    A_target = base_A + (A_target - base_A) * (1 - 0.95 * char_mix)\n                    B_target -= 22.0 * char_mix\n                L_target *= random.uniform(0.95, 1.05)\n                A_target += random.uniform(-2.5, 2.5)\n                B_target += random.uniform(-1.7, 1.7)\n                lab_val = lab[my, mx]\n                lab[my, mx, 0] = lab_val[0] * (1 - alpha) + L_target * alpha\n                lab[my, mx, 1] = lab_val[1] * (1 - alpha) + A_target * alpha\n                lab[my, mx, 2] = lab_val[2] * (1 - alpha) + B_target * alpha\n        lab_clipped = np.clip(lab, 0, 255).astype(np.uint8)\n        result = cv2.cvtColor(lab_clipped, cv2.COLOR_LAB2BGR).astype(np.float32)\n        bumps = gaussian_filter(self.fractal_noise((sub_h, sub_w), octaves=6, persistence=0.6), sigma=1.0)\n        bumps = (bumps - bumps.min()) / (bumps.max() - bumps.min() + 1e-12)\n        blister_mask = (bumps > 0.75).astype(np.float32) * mask_sub\n        spec = np.zeros_like(result, dtype=np.float32)\n        spec_val = 42.0  # harsh specular highlights\n        for c in range(3):\n            spec[y0:y1, x0:x1, c] += blister_mask * spec_val\n        spec = gaussian_filter(spec, sigma=1.1)\n        result = np.clip(result + spec * 0.82, 0, 255)\n        blur = cv2.GaussianBlur(result, (0, 0), sigmaX=15, sigmaY=15)\n        mask_3ch = np.dstack([feathered, feathered, feathered])\n        result = result * (1 - mask_3ch * 0.53) + blur * (mask_3ch * 0.53)\n        result = np.clip(result, 0, 255).astype(np.uint8)\n        hsv = cv2.cvtColor(result, cv2.COLOR_BGR2HSV).astype(np.float32)\n        hsv[..., 1] = hsv[..., 1] * (1 - 0.24 * mask_3ch[..., 0])\n        result = cv2.cvtColor(np.clip(hsv, 0, 255).astype(np.uint8), cv2.COLOR_HSV2BGR)\n        return result\n\n    def generate_burn(self, img, severity='severe'):\n        face_region = self.detect_face_region(img)\n        face_boundary_mask = self.create_face_mask(img.shape, face_region)\n        burn_mask = self.create_burn_mask(img.shape, face_region, face_boundary_mask)  # increased size_factor by default\n        out = self.apply_burn(img, burn_mask, severity=severity)\n        return out\n\n    def process_all_images(self, dataset_path, max_images=3000):\n        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n        image_files = []\n        for ext in image_extensions:\n            image_files.extend(Path(dataset_path).rglob(f'*{ext}'))\n            image_files.extend(Path(dataset_path).rglob(f'*{ext.upper()}'))\n        image_files = list(dict.fromkeys([str(p) for p in image_files]))[:max_images]\n        total_images = len(image_files)\n        print(f\"Found {total_images} images in dataset\")\n        print(f\"Processing ONLY first {total_images} images with SEVERE burns...\\n\")\n        stats = {'original': 0, 'burns_severe': 0, 'failed': 0}\n        for idx, img_path in enumerate(image_files):\n            try:\n                img = cv2.imread(img_path)\n                if img is None:\n                    stats['failed'] += 1\n                    print(f\"âœ— {idx+1}/{total_images}: Could not read {Path(img_path).name}\")\n                    continue\n                h, w = img.shape[:2]\n                if h > 1000 or w > 1000:\n                    scale = min(1000/h, 1000/w)\n                    img = cv2.resize(img, (int(w*scale), int(h*scale)))\n                base = f\"img_{idx:05d}\"\n                cv2.imwrite(f\"{self.output_dir}/original/{base}_orig.jpg\", img)\n                stats['original'] += 1\n                burned = self.generate_burn(img.copy(), severity='severe')\n                cv2.imwrite(f\"{self.output_dir}/with_burns/{base}_severe.jpg\", burned)\n                stats['burns_severe'] += 1\n                if (idx + 1) % 10 == 0 or (idx + 1) == total_images:\n                    print(f\"âœ“ Progress: {idx+1}/{total_images} ({(idx+1)/total_images*100:.1f}%)\")\n            except Exception as e:\n                stats['failed'] += 1\n                print(f\"âœ— Error processing {Path(img_path).name}: {e}\")\n        print(\"\\n\" + \"=\"*60)\n        print(\"PROCESSING COMPLETE\")\n        print(\"=\"*60)\n        for k, v in stats.items():\n            print(f\"  {k}: {v}\")\n        print(f\"\\nTotal images processed: {stats['original']}\")\n        print(f\"Total burn variations created: {stats['burns_severe']}\")\n        return stats\n\n    def create_comparison(self, dataset_path, num_samples=3):\n        image_files = []\n        for ext in ['.jpg', '.jpeg', '.png']:\n            image_files.extend(list(Path(dataset_path).rglob(f'*{ext}'))[:num_samples])\n        image_files = list(dict.fromkeys([str(p) for p in image_files]))[:num_samples]\n        if not image_files:\n            print(\"No images found\")\n            return\n        fig, axes = plt.subplots(len(image_files), 2, figsize=(9, 4.5 * len(image_files)))\n        if len(image_files) == 1:\n            axes = axes.reshape(1, -1)\n        for idx, img_path in enumerate(image_files):\n            img = cv2.imread(img_path)\n            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            h, w = img_rgb.shape[:2]\n            if h > 400:\n                scale = 400 / h\n                img_rgb = cv2.resize(img_rgb, (int(w*scale), int(h*scale)))\n                img = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n            axes[idx, 0].imshow(img_rgb)\n            axes[idx, 0].set_title('Original', fontsize=12)\n            axes[idx, 0].axis('off')\n            severe = self.generate_burn(img.copy(), 'severe')\n            axes[idx, 1].imshow(cv2.cvtColor(severe, cv2.COLOR_BGR2RGB))\n            axes[idx, 1].set_title('Severe Burn', fontsize=11)\n            axes[idx, 1].axis('off')\n        plt.tight_layout()\n        out = f'{self.output_dir}/comparison.png'\n        plt.savefig(out, dpi=150, bbox_inches='tight')\n        plt.show()\n        print(f\"âœ“ Saved: {out}\")\n\nif __name__ == \"__main__\":\n    print(\"ðŸ”¬ Realistic Burn Generator (Face-Constrained)\")\n    print(\"=\" * 60 + \"\\n\")\n    gen = RealisticBurnGenerator(output_dir=\"burn_augmented\", seed=42)\n    print(\"ðŸ“Š Creating comparison grid...\\n\")\n    gen.create_comparison(path, num_samples=3)\n    print(\"\\nðŸ”„ Processing ONLY first 3000 images in dataset with SEVERE burns...\\n\")\n    gen.process_all_images(path, max_images=3000)\n    print(\"\\nâœ… Done! 3000 images processed with severe and slightly larger burns strictly confined to facial regions!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T07:11:57.088820Z","iopub.execute_input":"2025-11-20T07:11:57.089139Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\ndef create_zip_from_folder(folder_path, zip_name='burn_output.zip'):\n    \"\"\"\n    Compress the entire folder into a ZIP archive.\n    \"\"\"\n    shutil.make_archive(base_name=zip_name.replace('.zip', ''),format='zip', root_dir=\"/kaggle/working/burn_augmented\")\n\n\ncreate_zip_from_folder('burn_augmented', 'burn_output.zip')\nprint(\"ðŸš€ ZIP file created: burn_output.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T08:49:59.312104Z","iopub.execute_input":"2025-11-20T08:49:59.312452Z","iopub.status.idle":"2025-11-20T08:50:51.059926Z","shell.execute_reply.started":"2025-11-20T08:49:59.312426Z","shell.execute_reply":"2025-11-20T08:50:51.058737Z"}},"outputs":[],"execution_count":null}]}